{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYtQ0mYu8iPGRcdVhtUU4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulrajpr/AdvancedHyperParameterOptimisation/blob/CrossValidation/CrossValidationBasics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross valistions are Demonstrated in the followoing methods\n",
        "\n",
        "1. K fold Cross Validation - # K Folds\n",
        "2. Repeated K Fold Cross Validation - # n repeations K fold by suffliing dataset before fold splitting of each times\n",
        "3. Stratified K Fold Cross Validation - # Stratification of all target class across all the folds\n",
        "4. Leave One out Cross Validation # Leaving one observation out in each iterations and remain dataset bcomes trainset - folds = len(dataset)\n",
        "5. Leave P out cross validation  # leaving p observations out in each iterations and rest becomes the test set."
      ],
      "metadata": {
        "id": "LSwhBahFJT3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : sklearn.model_selection import cross_validation -- > returns dictionary of training and testing scores"
      ],
      "metadata": {
        "id": "xGLr70FQRqUi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CywHmZfqHUbB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ],
      "metadata": {
        "id": "YkX9gLJhHpsF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_breast_cancer()"
      ],
      "metadata": {
        "id": "bTOf84LIHxph"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat(\n",
        "    [pd.DataFrame(data.data, columns = data.feature_names),\n",
        "     pd.Series(data.target).rename('target')],axis = 1)"
      ],
      "metadata": {
        "id": "nQ6qOOIHH2SD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0XOKmK0H4FC",
        "outputId": "158b1a36-9ef5-41c0-87c6-4a46eb1f5dad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            " 30  target                   569 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCfx4-OgIfpO",
        "outputId": "e341eee9-e4a6-4d9b-b3d9-91a76f29dcf8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "target                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsE8VrZNIldN",
        "outputId": "b36240ab-a3a1-4af9-feb7-575e43532589"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.627417\n",
              "0    0.372583\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('target', axis = 1)\n",
        "y = df['target']"
      ],
      "metadata": {
        "id": "PfZmdM68IxgH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "a2VLUkIbI-ht"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size = 0.7, random_state = 100, stratify = y)"
      ],
      "metadata": {
        "id": "abjJxAczJEwP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Fold Cross Validation"
      ],
      "metadata": {
        "id": "XPtjN6QrKgso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate"
      ],
      "metadata": {
        "id": "cjJIpv1-KrC0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "nYDw5FSQR6B7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "9Q8-UR_WR1uG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = KFold(n_splits= 5, shuffle = True, random_state = 100)"
      ],
      "metadata": {
        "id": "eTwLu4gKS6ns"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit = LogisticRegression(penalty = 'l2',C = 10,max_iter = 10000, random_state = 100)\n",
        "\n",
        "cv_scoring = cross_validate(logit, X = X_train, y = y_train, scoring = 'accuracy', n_jobs = -1, return_train_score = True, cv = split)\n",
        "\n",
        "cv_scoring"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKBSfSVsJRk8",
        "outputId": "fab08529-b452-40b0-d6de-6013a6da31f4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([2.63966465, 3.64597678, 2.36425638, 2.66379952, 1.4042325 ]),\n",
              " 'score_time': array([0.01035261, 0.00451875, 0.00317359, 0.00319529, 0.00181651]),\n",
              " 'test_score': array([0.9625    , 0.975     , 0.9625    , 0.93670886, 0.96202532]),\n",
              " 'train_score': array([0.97798742, 0.97798742, 0.98113208, 0.99059561, 0.98119122])}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scoring['train_score']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mkGv9v-NL34",
        "outputId": "65c9f082-fae6-45d3-a84e-51220405c210"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97798742, 0.97798742, 0.98113208, 0.99059561, 0.98119122])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scoring['test_score']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwYYIfwbPOrc",
        "outputId": "a1eeea95-787d-44fe-d194-67454daa5da0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9625    , 0.975     , 0.9625    , 0.93670886, 0.96202532])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train scoring : ',np.mean(cv_scoring['train_score']),' +/- ' ,np.std(cv_scoring['train_score']))\n",
        "print('test scoring : ',np.mean(cv_scoring['test_score']),' +/- ' ,np.std(cv_scoring['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYhFlXKWPTJ9",
        "outputId": "e43dac1a-6d03-4001-b28e-a84842027d7d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train scoring :  0.9817787504189586  +/-  0.00463138779857402\n",
            "test scoring :  0.959746835443038  +/-  0.012520052814599933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Repeated K Fold Cross Validstion"
      ],
      "metadata": {
        "id": "f1XdM7kHRaer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedKFold"
      ],
      "metadata": {
        "id": "AJclu1neRzWG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = RepeatedKFold(n_splits = 5,random_state = 100)"
      ],
      "metadata": {
        "id": "V5tbGbuaTDWC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit = LogisticRegression(penalty = 'l2',C = 10,max_iter = 10000, random_state = 100)\n",
        "\n",
        "cv_scoring = cross_validate(logit, X = X_train, y = y_train, scoring = 'accuracy', n_jobs = -1, return_train_score = True, cv = split)\n",
        "\n",
        "cv_scoring"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1RIpXikPbm6",
        "outputId": "fe26e04b-a1e1-4332-a7be-042eb4c2ebc9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([2.84564352, 3.54206395, 3.85121155, 3.92794275, 1.76331687,\n",
              "        1.8257103 , 1.83961272, 2.25232148, 1.90453839, 1.52543783,\n",
              "        1.58565378, 1.35801864, 0.51285243, 1.77391171, 2.20073676,\n",
              "        1.98206925, 2.23932934, 1.67640924, 1.692029  , 1.89165449,\n",
              "        2.51727772, 2.06062531, 2.14800787, 1.79746008, 1.62814999,\n",
              "        1.70726776, 1.8363657 , 1.99213958, 1.20508552, 2.29301882,\n",
              "        1.71144128, 2.0145421 , 1.99977112, 2.20652723, 1.81363559,\n",
              "        1.95809817, 1.40373755, 1.84648752, 1.95894766, 1.95139527,\n",
              "        2.6844418 , 2.53099322, 2.62821794, 1.86092329, 1.47401905,\n",
              "        2.05011845, 1.10196614, 0.47798061, 1.53170919, 1.3912499 ]),\n",
              " 'score_time': array([0.0028336 , 0.00272369, 0.00315762, 0.00304413, 0.00311708,\n",
              "        0.00317192, 0.00309587, 0.0030973 , 0.0031147 , 0.00327277,\n",
              "        0.00302148, 0.00307751, 0.00313449, 0.00339913, 0.00307083,\n",
              "        0.00316048, 0.00309253, 0.00309587, 0.00314879, 0.00311995,\n",
              "        0.00327277, 0.00311565, 0.0032382 , 0.00306845, 0.00306129,\n",
              "        0.00311446, 0.0031209 , 0.00310636, 0.00315523, 0.00314665,\n",
              "        0.00314856, 0.00307059, 0.00302911, 0.00310397, 0.003124  ,\n",
              "        0.00326037, 0.00310636, 0.00313878, 0.00303888, 0.00315332,\n",
              "        0.00318456, 0.00316334, 0.00312591, 0.00309873, 0.00311303,\n",
              "        0.00302482, 0.00315571, 0.00337386, 0.00312662, 0.00182104]),\n",
              " 'test_score': array([0.9625    , 0.975     , 0.9625    , 0.93670886, 0.96202532,\n",
              "        0.975     , 0.9625    , 1.        , 0.94936709, 0.92405063,\n",
              "        0.9625    , 0.975     , 0.975     , 0.96202532, 0.94936709,\n",
              "        0.9375    , 0.95      , 0.95      , 0.97468354, 0.98734177,\n",
              "        0.95      , 0.975     , 0.9625    , 0.94936709, 0.97468354,\n",
              "        0.95      , 0.9375    , 0.9625    , 0.98734177, 0.96202532,\n",
              "        0.975     , 0.925     , 0.975     , 0.94936709, 0.98734177,\n",
              "        0.975     , 0.9875    , 0.9       , 0.98734177, 0.98734177,\n",
              "        0.9875    , 0.9625    , 0.975     , 0.97468354, 0.92405063,\n",
              "        0.975     , 0.925     , 1.        , 0.94936709, 0.97468354]),\n",
              " 'train_score': array([0.97798742, 0.97798742, 0.98113208, 0.99059561, 0.98119122,\n",
              "        0.97484277, 0.98742138, 0.97169811, 0.98432602, 0.98119122,\n",
              "        0.97484277, 0.98113208, 0.97484277, 0.98746082, 0.97805643,\n",
              "        0.98113208, 0.99056604, 0.98113208, 0.97492163, 0.98746082,\n",
              "        0.98427673, 0.98427673, 0.96855346, 0.98746082, 0.98119122,\n",
              "        0.98113208, 0.98742138, 0.98742138, 0.97805643, 0.98119122,\n",
              "        0.97798742, 0.99371069, 0.97169811, 0.98119122, 0.97805643,\n",
              "        0.98427673, 0.97484277, 0.98742138, 0.97492163, 0.98119122,\n",
              "        0.97484277, 0.98113208, 0.97798742, 0.98119122, 0.99059561,\n",
              "        0.98742138, 0.97169811, 0.97484277, 0.98432602, 0.98119122])}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train scoring : ',np.mean(cv_scoring['train_score']),' +/- ' ,np.std(cv_scoring['train_score']))\n",
        "print('test scoring : ',np.mean(cv_scoring['test_score']),' +/- ' ,np.std(cv_scoring['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifA-iee1QrxT",
        "outputId": "5fc1602b-59da-468f-a88d-49f6ff4bcac0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train scoring :  0.9810285680487373  +/-  0.005659437934919945\n",
            "test scoring :  0.9628132911392406  +/-  0.02115566069046581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statified K Fold Cross Validation"
      ],
      "metadata": {
        "id": "m8JjlAWrRABR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "metadata": {
        "id": "-IKf4hc4Q8dk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = StratifiedKFold(n_splits= 5, shuffle = True, random_state = 100)"
      ],
      "metadata": {
        "id": "Y827ra_hRIRQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit = LogisticRegression(penalty = 'l2',C = 10,max_iter = 10000, random_state = 100)\n",
        "\n",
        "cv_scoring = cross_validate(logit, X = X_train, y = y_train, scoring = 'accuracy', n_jobs = -1, return_train_score = True, cv = split)\n",
        "\n",
        "cv_scoring"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRDAX634RIKH",
        "outputId": "af7aeba3-f50e-4cfe-d678-d7bea55ab4c2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([1.57359219, 1.89248657, 1.77823424, 0.44270921, 1.4075923 ]),\n",
              " 'score_time': array([0.00315356, 0.00309396, 0.0031538 , 0.00364709, 0.00179958]),\n",
              " 'test_score': array([0.975     , 0.9375    , 0.9375    , 0.93670886, 0.97468354]),\n",
              " 'train_score': array([0.98427673, 0.98113208, 0.98427673, 0.97178683, 0.98432602])}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train scoring : ',np.mean(cv_scoring['train_score']),' +/- ' ,np.std(cv_scoring['train_score']))\n",
        "print('test scoring : ',np.mean(cv_scoring['test_score']),' +/- ' ,np.std(cv_scoring['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA-IbTv3Rid1",
        "outputId": "3e62dec9-3a70-4f5b-e31c-bfacefe8b557"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train scoring :  0.9811596774511543  +/-  0.004843732119360722\n",
            "test scoring :  0.9522784810126582  +/-  0.018425386634113475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave One Out Cross Validation"
      ],
      "metadata": {
        "id": "I98GT_YQR-ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut"
      ],
      "metadata": {
        "id": "GcijP8_eRmQu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = LeaveOneOut()"
      ],
      "metadata": {
        "id": "7FporOGcSMsN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit = LogisticRegression(penalty = 'l2',C = 10,max_iter = 10000, random_state = 100)\n",
        "\n",
        "cv_scoring = cross_validate(logit, X = X_train, y = y_train, scoring = 'accuracy', n_jobs = -1, return_train_score = True, cv = split)\n",
        "\n",
        "cv_scoring"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp5rgW2XSVxo",
        "outputId": "1905b7d3-a888-4d22-ed6a-4a968f11e681"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([2.14442682, 0.73047376, 0.82653093, 1.83848715, 2.20495915,\n",
              "        2.44991899, 1.81923437, 0.3419497 , 2.33593822, 1.96047115,\n",
              "        2.19363546, 1.51561928, 2.12299299, 2.48227644, 2.00569463,\n",
              "        2.50874186, 1.96613121, 1.94474602, 1.81200099, 1.93163109,\n",
              "        2.09927249, 2.48250294, 1.771523  , 0.63472319, 2.25763607,\n",
              "        1.66022062, 1.96910453, 2.3406167 , 1.97197652, 2.00362492,\n",
              "        1.83323026, 1.68220997, 2.15848589, 1.78925753, 1.77938271,\n",
              "        1.6096437 , 2.342731  , 1.62573433, 1.98929501, 2.32460499,\n",
              "        1.77530098, 2.20393515, 3.34723711, 1.95685911, 2.0175128 ,\n",
              "        2.22233963, 1.82283306, 2.36694527, 1.71097875, 1.99156809,\n",
              "        2.87603354, 2.21520042, 1.97637105, 2.15076661, 0.57892561,\n",
              "        0.49940419, 2.15944266, 2.2117312 , 1.73515987, 2.20218325,\n",
              "        1.93297911, 2.17998719, 2.47283053, 2.00622392, 2.22922111,\n",
              "        2.25811577, 1.95751643, 2.08264923, 2.44023299, 2.06322837,\n",
              "        2.31679893, 2.26358962, 2.05031276, 2.21654892, 2.27023578,\n",
              "        1.85826349, 1.96281624, 1.50339079, 2.10428691, 2.1754899 ,\n",
              "        2.07465315, 2.45718241, 1.89258099, 1.92092752, 1.64386988,\n",
              "        2.05348063, 2.02709341, 1.99045157, 1.83638453, 1.76779199,\n",
              "        1.95631886, 2.10506558, 2.61761951, 1.75319695, 1.82322598,\n",
              "        2.2462914 , 2.6274457 , 1.63706112, 2.32852101, 0.81664848,\n",
              "        2.14482999, 1.64640927, 1.96235991, 1.79217172, 1.76625085,\n",
              "        2.12284017, 1.87526631, 1.80736184, 1.911695  , 2.41533566,\n",
              "        2.11767697, 1.98164415, 2.31112432, 2.27689624, 1.90088224,\n",
              "        2.34124351, 2.00060225, 1.98966098, 2.25887752, 3.17192268,\n",
              "        2.24033809, 1.95619178, 1.87989545, 2.63866615, 2.1549871 ,\n",
              "        2.34386945, 2.66543221, 3.45590305, 3.35051656, 2.63544488,\n",
              "        2.37937021, 2.31390762, 2.12122059, 2.11929965, 2.96948957,\n",
              "        2.22597051, 1.97987461, 1.62034202, 1.81780481, 2.0274477 ,\n",
              "        2.27036524, 1.76873016, 2.19662595, 2.13801908, 2.22349095,\n",
              "        2.17917156, 2.27984571, 1.77991986, 2.14693785, 1.85960031,\n",
              "        2.42627788, 2.47197556, 2.25013041, 2.08236575, 2.04947162,\n",
              "        2.470788  , 2.18256283, 1.96457672, 1.95340395, 2.05240822,\n",
              "        2.09761047, 1.89418793, 2.15729523, 1.87000704, 1.82850504,\n",
              "        2.48790574, 2.07366467, 0.82071471, 2.12468863, 1.82067227,\n",
              "        2.30833507, 2.07683992, 2.00434828, 1.72289228, 1.91113472,\n",
              "        1.99611831, 1.91378903, 2.26519561, 2.13109303, 1.91176057,\n",
              "        0.62625074, 1.89145446, 2.05036139, 1.7950995 , 2.53483725,\n",
              "        1.90648508, 2.06626701, 1.96935701, 2.48333406, 1.94709802,\n",
              "        1.90972638, 2.39384651, 1.727566  , 2.39843249, 2.0738318 ,\n",
              "        2.14911342, 2.07634807, 2.15304279, 2.0053587 , 2.20693851,\n",
              "        1.72367644, 2.0845499 , 2.07413197, 1.68056393, 1.89948082,\n",
              "        2.35515976, 2.32439065, 2.17939973, 1.87755823, 3.19035816,\n",
              "        3.11126614, 2.21763945, 2.11852908, 1.7542417 , 2.16873026,\n",
              "        2.33490825, 1.91085649, 1.74436116, 2.05824852, 2.17530847,\n",
              "        2.29839945, 1.53244543, 2.52896023, 1.81419039, 2.03726506,\n",
              "        1.96764302, 1.84707379, 2.09967041, 1.89425397, 2.23439217,\n",
              "        2.08247304, 1.86130118, 2.06229758, 1.96473646, 2.5778029 ,\n",
              "        2.36344576, 1.64883804, 2.44923401, 1.72608519, 1.98743773,\n",
              "        2.44215345, 1.87399316, 2.23260021, 2.41875196, 2.56224227,\n",
              "        2.25828052, 2.08378553, 2.83490801, 1.69972372, 2.00576353,\n",
              "        2.29660773, 2.32559991, 1.88669682, 2.13691998, 2.33772063,\n",
              "        2.22851801, 1.81579185, 2.06779385, 2.22646475, 1.6239295 ,\n",
              "        1.84545994, 0.70345831, 2.460006  , 2.113451  , 2.1774087 ,\n",
              "        2.32230258, 2.30512691, 1.91019726, 2.01854515, 2.57688546,\n",
              "        2.33591557, 2.12770486, 3.22816348, 3.46450663, 2.02281904,\n",
              "        2.00348639, 1.91634655, 1.95442653, 2.11303926, 0.54196262,\n",
              "        1.63263011, 1.77249026, 2.03225064, 1.99064207, 2.25796509,\n",
              "        1.77524424, 1.72737145, 2.31261444, 2.17409563, 1.94996095,\n",
              "        1.63206363, 2.43292618, 1.90883255, 2.75555849, 3.35115051,\n",
              "        0.46725631, 1.96451187, 1.07639146, 2.72144103, 2.18803215,\n",
              "        2.61325645, 1.91731095, 1.86042762, 2.23675728, 1.97715282,\n",
              "        2.0215292 , 1.98124576, 1.78288555, 1.65393615, 2.15462565,\n",
              "        1.86686063, 1.67869306, 1.69802976, 1.90352035, 1.72490644,\n",
              "        2.19555235, 1.53173685, 2.01347828, 1.65609813, 2.56436682,\n",
              "        1.63601995, 2.45420766, 2.12228584, 1.91810441, 2.39072227,\n",
              "        2.00210977, 1.99650192, 1.67438173, 1.93876719, 2.80335522,\n",
              "        2.24692059, 2.12334347, 2.57604146, 2.29009295, 2.45329022,\n",
              "        2.04173255, 2.09435534, 1.88256788, 2.17597246, 1.72800756,\n",
              "        2.30812502, 2.24544907, 1.66580653, 1.13446665, 2.19472885,\n",
              "        1.94469142, 2.0378406 , 1.96893191, 2.45974851, 2.51739478,\n",
              "        2.26024175, 2.19427347, 0.85090756, 1.86907125, 2.8380456 ,\n",
              "        2.18051004, 1.84784889, 2.01967072, 1.15725517, 2.2556572 ,\n",
              "        2.03545237, 1.948946  , 2.34035087, 2.50932646, 1.60851359,\n",
              "        1.91294003, 2.52975965, 2.38620496, 2.11065292, 1.95332694,\n",
              "        1.98026323, 2.86325288, 2.20449495, 2.34056425, 1.75012994,\n",
              "        2.04847193, 2.22520852, 2.48736072, 2.06200409, 1.99603915,\n",
              "        1.70860291, 1.62032199, 2.12821102, 2.86693859, 1.90863681,\n",
              "        2.54739285, 2.09984732, 1.84712076, 2.08221817, 2.11730552,\n",
              "        1.68737507, 1.88673663, 3.23984551, 1.96164823, 0.73419237,\n",
              "        1.81836009, 2.07550144, 1.32640386]),\n",
              " 'score_time': array([0.00302553, 0.00304961, 0.0033145 , 0.00340867, 0.00306797,\n",
              "        0.00297761, 0.00303054, 0.00295353, 0.00302482, 0.00298786,\n",
              "        0.00299644, 0.00306368, 0.0029676 , 0.002949  , 0.00303316,\n",
              "        0.00298309, 0.00301218, 0.00298452, 0.00302696, 0.00271678,\n",
              "        0.00299525, 0.00339794, 0.00883722, 0.00291133, 0.00299716,\n",
              "        0.00291991, 0.00296521, 0.00296354, 0.00301766, 0.00372624,\n",
              "        0.00295711, 0.00297022, 0.00299907, 0.00301003, 0.00299811,\n",
              "        0.00294399, 0.00293684, 0.00295639, 0.0031774 , 0.00294185,\n",
              "        0.00295663, 0.00306678, 0.00298643, 0.00321317, 0.00298619,\n",
              "        0.00294685, 0.00299811, 0.00296998, 0.00293207, 0.00298882,\n",
              "        0.00299168, 0.00301409, 0.0029664 , 0.00302505, 0.00312424,\n",
              "        0.00297642, 0.00295949, 0.00293779, 0.00298333, 0.00302577,\n",
              "        0.00305367, 0.00299978, 0.00292349, 0.00305843, 0.00300288,\n",
              "        0.00303459, 0.00293541, 0.00296354, 0.00294709, 0.00294948,\n",
              "        0.00291419, 0.00301576, 0.00291276, 0.00296664, 0.00295281,\n",
              "        0.0029633 , 0.00292277, 0.0029974 , 0.00290918, 0.00294137,\n",
              "        0.00298047, 0.00297022, 0.00299764, 0.00292277, 0.00304508,\n",
              "        0.00292468, 0.00296545, 0.00292778, 0.00298262, 0.00298023,\n",
              "        0.00298357, 0.0030179 , 0.00298285, 0.00294065, 0.00317597,\n",
              "        0.00302696, 0.00309825, 0.00300407, 0.00377727, 0.00296092,\n",
              "        0.00299716, 0.00292206, 0.00316691, 0.00294232, 0.00296712,\n",
              "        0.00313997, 0.00305247, 0.00296474, 0.00302625, 0.00289583,\n",
              "        0.0030067 , 0.00297332, 0.00300479, 0.00299621, 0.00301194,\n",
              "        0.0029881 , 0.00300694, 0.00295663, 0.00297093, 0.00293899,\n",
              "        0.00296307, 0.00298858, 0.00303078, 0.00316358, 0.00326228,\n",
              "        0.00298119, 0.00306582, 0.00244641, 0.00958514, 0.00294638,\n",
              "        0.00295544, 0.00297308, 0.00301552, 0.00298429, 0.00294685,\n",
              "        0.00297236, 0.0029242 , 0.00298309, 0.00293469, 0.00297022,\n",
              "        0.00296807, 0.00303125, 0.00295901, 0.00295186, 0.0029707 ,\n",
              "        0.00296712, 0.00255418, 0.00296712, 0.00294304, 0.00300765,\n",
              "        0.00296259, 0.00302172, 0.00295973, 0.00297379, 0.00301623,\n",
              "        0.00292945, 0.00296259, 0.00300598, 0.00302839, 0.00299215,\n",
              "        0.00293374, 0.00294852, 0.00295067, 0.00298333, 0.00301814,\n",
              "        0.00292993, 0.0029192 , 0.00295424, 0.00296831, 0.00295019,\n",
              "        0.00311184, 0.00290513, 0.00295115, 0.0030098 , 0.00293231,\n",
              "        0.00294995, 0.00298691, 0.00294614, 0.00295377, 0.00301456,\n",
              "        0.00292015, 0.00292373, 0.00292945, 0.00302386, 0.00299287,\n",
              "        0.00303912, 0.00296116, 0.00419545, 0.00305867, 0.00297928,\n",
              "        0.00315428, 0.00301075, 0.00294042, 0.00298047, 0.00298262,\n",
              "        0.00299144, 0.00301623, 0.00293851, 0.00292706, 0.00300431,\n",
              "        0.00283337, 0.00299621, 0.00281572, 0.00296974, 0.00291896,\n",
              "        0.00525403, 0.00295687, 0.0032227 , 0.00294065, 0.00332475,\n",
              "        0.0029335 , 0.00310063, 0.00305271, 0.00290513, 0.00298548,\n",
              "        0.0029645 , 0.00296378, 0.00301743, 0.00249553, 0.00307155,\n",
              "        0.00303698, 0.00298023, 0.0030005 , 0.00470519, 0.00295591,\n",
              "        0.00296974, 0.00318408, 0.00294781, 0.003268  , 0.00336099,\n",
              "        0.00292611, 0.00296211, 0.00313735, 0.00301456, 0.00297451,\n",
              "        0.00297642, 0.00294042, 0.00297809, 0.00311732, 0.00298667,\n",
              "        0.00305057, 0.00300264, 0.00296879, 0.00300694, 0.00849819,\n",
              "        0.00303102, 0.003016  , 0.00294495, 0.00299358, 0.00296855,\n",
              "        0.00296497, 0.00302052, 0.0029037 , 0.00296593, 0.00290966,\n",
              "        0.00296617, 0.00289297, 0.00294614, 0.00293565, 0.00296187,\n",
              "        0.00301409, 0.0032115 , 0.0029335 , 0.00296569, 0.00293064,\n",
              "        0.00296807, 0.00297475, 0.00300527, 0.00298929, 0.00326014,\n",
              "        0.00301838, 0.00243855, 0.00244355, 0.00294065, 0.0029366 ,\n",
              "        0.00299621, 0.00293994, 0.00399375, 0.00298905, 0.0029552 ,\n",
              "        0.00290394, 0.00299335, 0.00299811, 0.00298452, 0.00289202,\n",
              "        0.0029223 , 0.00299788, 0.00298047, 0.00326991, 0.0029366 ,\n",
              "        0.00290179, 0.00289035, 0.00299382, 0.0030036 , 0.00299025,\n",
              "        0.00300527, 0.00301147, 0.0029335 , 0.00294423, 0.00408006,\n",
              "        0.00293279, 0.00293303, 0.00293159, 0.00297999, 0.00298929,\n",
              "        0.00295258, 0.002913  , 0.00294971, 0.00294733, 0.0029223 ,\n",
              "        0.00290942, 0.00422597, 0.0029707 , 0.00296068, 0.00303555,\n",
              "        0.00296712, 0.007658  , 0.00301862, 0.00292373, 0.00295019,\n",
              "        0.00295234, 0.00299764, 0.00295568, 0.00299621, 0.00293541,\n",
              "        0.00294137, 0.00298905, 0.00332832, 0.0028944 , 0.00301433,\n",
              "        0.00299644, 0.00297022, 0.00293207, 0.00299072, 0.00517964,\n",
              "        0.00295401, 0.00312757, 0.0029521 , 0.00299644, 0.00298285,\n",
              "        0.00295949, 0.00293255, 0.00295258, 0.00297046, 0.00290632,\n",
              "        0.00291657, 0.00290656, 0.00290108, 0.0029726 , 0.00289059,\n",
              "        0.0029788 , 0.0029006 , 0.00515676, 0.0029428 , 0.00296617,\n",
              "        0.00292635, 0.0029819 , 0.00293064, 0.00293994, 0.00299478,\n",
              "        0.00300455, 0.00296712, 0.00246453, 0.00295591, 0.00301003,\n",
              "        0.00291729, 0.00302792, 0.00301695, 0.00293708, 0.00291061,\n",
              "        0.0024519 , 0.00292611, 0.0029974 , 0.00295424, 0.00301266,\n",
              "        0.00297928, 0.00289273, 0.0029633 , 0.00295115, 0.00275874,\n",
              "        0.00250244, 0.00484991, 0.00291252, 0.00296974, 0.002913  ,\n",
              "        0.00298071, 0.00276518, 0.00302267, 0.00290561, 0.00295377,\n",
              "        0.00291824, 0.00302482, 0.00292587, 0.00306487, 0.00295138,\n",
              "        0.00292802, 0.00296783, 0.00166106]),\n",
              " 'test_score': array([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
              "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1.]),\n",
              " 'train_score': array([0.97984887, 0.97732997, 0.97732997, 0.98236776, 0.97984887,\n",
              "        0.97984887, 0.97984887, 0.97732997, 0.98488665, 0.97984887,\n",
              "        0.97984887, 0.97984887, 0.98236776, 0.97984887, 0.97984887,\n",
              "        0.97984887, 0.98236776, 0.97984887, 0.97732997, 0.97984887,\n",
              "        0.97984887, 0.97984887, 0.98488665, 0.97732997, 0.98236776,\n",
              "        0.98488665, 0.97984887, 0.98236776, 0.98488665, 0.97984887,\n",
              "        0.97984887, 0.98488665, 0.98236776, 0.98236776, 0.97984887,\n",
              "        0.97984887, 0.98488665, 0.97732997, 0.97984887, 0.97984887,\n",
              "        0.98236776, 0.97984887, 0.97984887, 0.97984887, 0.97984887,\n",
              "        0.98236776, 0.97984887, 0.98488665, 0.98236776, 0.98236776,\n",
              "        0.98236776, 0.98488665, 0.97732997, 0.98488665, 0.97732997,\n",
              "        0.97984887, 0.98236776, 0.98236776, 0.98236776, 0.97984887,\n",
              "        0.97984887, 0.98488665, 0.97984887, 0.97732997, 0.98236776,\n",
              "        0.98236776, 0.98488665, 0.98236776, 0.98236776, 0.98236776,\n",
              "        0.98236776, 0.98236776, 0.97984887, 0.98236776, 0.98740554,\n",
              "        0.98236776, 0.97984887, 0.97984887, 0.97984887, 0.98236776,\n",
              "        0.98236776, 0.98236776, 0.97984887, 0.98236776, 0.97984887,\n",
              "        0.97984887, 0.97984887, 0.98236776, 0.97984887, 0.98488665,\n",
              "        0.98488665, 0.97984887, 0.97984887, 0.97984887, 0.97984887,\n",
              "        0.98236776, 0.97984887, 0.97984887, 0.98236776, 0.97732997,\n",
              "        0.98236776, 0.97984887, 0.97984887, 0.97984887, 0.98236776,\n",
              "        0.98236776, 0.98236776, 0.98488665, 0.97984887, 0.98740554,\n",
              "        0.98488665, 0.98236776, 0.98236776, 0.98236776, 0.97984887,\n",
              "        0.97984887, 0.98236776, 0.97984887, 0.97984887, 0.97984887,\n",
              "        0.98488665, 0.97984887, 0.98740554, 0.98236776, 0.97984887,\n",
              "        0.98236776, 0.97732997, 0.97984887, 0.98236776, 0.97984887,\n",
              "        0.97984887, 0.98236776, 0.97984887, 0.97984887, 0.98236776,\n",
              "        0.97984887, 0.97984887, 0.97984887, 0.98488665, 0.98236776,\n",
              "        0.97984887, 0.98236776, 0.97984887, 0.98236776, 0.97984887,\n",
              "        0.98488665, 0.97984887, 0.97984887, 0.97984887, 0.98488665,\n",
              "        0.97984887, 0.97984887, 0.98236776, 0.98236776, 0.97984887,\n",
              "        0.98236776, 0.97984887, 0.97984887, 0.97984887, 0.98488665,\n",
              "        0.97984887, 0.97984887, 0.97984887, 0.97984887, 0.97984887,\n",
              "        0.98236776, 0.97984887, 0.97732997, 0.97984887, 0.97984887,\n",
              "        0.97984887, 0.97984887, 0.98488665, 0.98488665, 0.98236776,\n",
              "        0.97984887, 0.97984887, 0.98236776, 0.97984887, 0.97984887,\n",
              "        0.97984887, 0.98488665, 0.98488665, 0.98236776, 0.97984887,\n",
              "        0.97984887, 0.98488665, 0.98236776, 0.98236776, 0.97984887,\n",
              "        0.97984887, 0.97984887, 0.98488665, 0.97984887, 0.97984887,\n",
              "        0.98236776, 0.97984887, 0.97984887, 0.97984887, 0.98236776,\n",
              "        0.98488665, 0.98488665, 0.98236776, 0.97732997, 0.97984887,\n",
              "        0.97984887, 0.97984887, 0.98236776, 0.97984887, 0.97984887,\n",
              "        0.97984887, 0.98236776, 0.97984887, 0.98236776, 0.98236776,\n",
              "        0.97984887, 0.97984887, 0.98488665, 0.98236776, 0.97984887,\n",
              "        0.98236776, 0.97984887, 0.98236776, 0.97984887, 0.98236776,\n",
              "        0.98488665, 0.98236776, 0.97984887, 0.97984887, 0.98236776,\n",
              "        0.97984887, 0.98236776, 0.98236776, 0.97984887, 0.98236776,\n",
              "        0.97984887, 0.97984887, 0.98236776, 0.97984887, 0.98236776,\n",
              "        0.97984887, 0.98236776, 0.97984887, 0.97984887, 0.97984887,\n",
              "        0.97984887, 0.98236776, 0.98236776, 0.97984887, 0.97984887,\n",
              "        0.97984887, 0.98236776, 0.98236776, 0.97984887, 0.97984887,\n",
              "        0.97984887, 0.97984887, 0.98488665, 0.98236776, 0.98236776,\n",
              "        0.98236776, 0.97732997, 0.98236776, 0.98488665, 0.98488665,\n",
              "        0.98236776, 0.97984887, 0.98236776, 0.97732997, 0.97984887,\n",
              "        0.98236776, 0.97984887, 0.98236776, 0.97984887, 0.97984887,\n",
              "        0.97984887, 0.98488665, 0.98236776, 0.98236776, 0.97732997,\n",
              "        0.97984887, 0.97984887, 0.97984887, 0.97984887, 0.98236776,\n",
              "        0.97984887, 0.97984887, 0.97984887, 0.97984887, 0.97984887,\n",
              "        0.97984887, 0.98488665, 0.98236776, 0.97984887, 0.97984887,\n",
              "        0.97732997, 0.98236776, 0.97732997, 0.98236776, 0.98488665,\n",
              "        0.98236776, 0.97732997, 0.97984887, 0.98236776, 0.98236776,\n",
              "        0.97984887, 0.97984887, 0.97984887, 0.98236776, 0.97984887,\n",
              "        0.98236776, 0.97984887, 0.97984887, 0.97984887, 0.98236776,\n",
              "        0.97984887, 0.98236776, 0.98236776, 0.97984887, 0.97984887,\n",
              "        0.98236776, 0.98236776, 0.97984887, 0.98236776, 0.97984887,\n",
              "        0.97732997, 0.98236776, 0.98236776, 0.97984887, 0.97984887,\n",
              "        0.98236776, 0.97984887, 0.97984887, 0.97984887, 0.97984887,\n",
              "        0.97984887, 0.98236776, 0.97984887, 0.98236776, 0.97984887,\n",
              "        0.97984887, 0.97984887, 0.98236776, 0.97732997, 0.97984887,\n",
              "        0.97984887, 0.97984887, 0.97984887, 0.98236776, 0.97984887,\n",
              "        0.97984887, 0.97984887, 0.97732997, 0.97984887, 0.98236776,\n",
              "        0.98236776, 0.98236776, 0.97984887, 0.97732997, 0.98236776,\n",
              "        0.97984887, 0.98236776, 0.97984887, 0.97984887, 0.98488665,\n",
              "        0.97984887, 0.97984887, 0.98236776, 0.98236776, 0.98236776,\n",
              "        0.97984887, 0.98488665, 0.97984887, 0.98236776, 0.97984887,\n",
              "        0.98488665, 0.98236776, 0.98236776, 0.97984887, 0.98236776,\n",
              "        0.97984887, 0.98236776, 0.97984887, 0.97984887, 0.98236776,\n",
              "        0.97984887, 0.98236776, 0.97984887, 0.97984887, 0.97984887,\n",
              "        0.97984887, 0.97984887, 0.97984887, 0.97984887, 0.97732997,\n",
              "        0.97984887, 0.97732997, 0.97984887])}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train scoring : ',np.mean(cv_scoring['train_score']),' +/- ' ,np.std(cv_scoring['train_score']))\n",
        "print('test scoring : ',np.mean(cv_scoring['test_score']),' +/- ' ,np.std(cv_scoring['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_xmsmigSX7M",
        "outputId": "495ca363-85c1-4ea3-fbc7-46d25b232b0b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train scoring :  0.9810386947331113  +/-  0.001977081762172984\n",
            "test scoring :  0.964824120603015  +/-  0.18422414854093827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave P Out Cross Validation"
      ],
      "metadata": {
        "id": "wJ7f0sq8SeV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeavePOut"
      ],
      "metadata": {
        "id": "G5rXf5_2ScAT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = LeavePOut(p = 2)"
      ],
      "metadata": {
        "id": "561NG3JeSp00"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit = LogisticRegression(penalty = 'l2',C = 10,max_iter = 10000, random_state = 100)\n",
        "\n",
        "cv_scoring = cross_validate(logit, X = X_train.head(100), y = y_train.head(100), scoring = 'accuracy', n_jobs = -1, return_train_score = True, cv = split)\n",
        "\n",
        "cv_scoring\n",
        "\n",
        "# This is going to take a lot of computation and time, so we are reducing the train size for quick fits of the models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "yXKqtTZtUk9u",
        "outputId": "1aa51eef-a5cc-4880-c9bd-c608e524cec4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-1d72dc4cfdbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcv_scoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcv_scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    268\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train scoring : ',np.mean(cv_scoring['train_score']),' +/- ' ,np.std(cv_scoring['train_score']))\n",
        "print('test scoring : ',np.mean(cv_scoring['test_score']),' +/- ' ,np.std(cv_scoring['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdvjBAkDUrot",
        "outputId": "b984b9a0-a650-4427-ef7d-fa6f94205a13"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train scoring :  0.9810386947331113  +/-  0.001977081762172984\n",
            "test scoring :  0.964824120603015  +/-  0.18422414854093827\n"
          ]
        }
      ]
    }
  ]
}